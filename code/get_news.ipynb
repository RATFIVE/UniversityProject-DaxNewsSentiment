{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exlplaination about this notebook\n",
    "\n",
    "In this notebook I gathered the Date, Headline and the news text from the links. \n",
    "The links where gathered in notebook `get_links.ipynb`!\n",
    "\n",
    "**Caution!** This code will take about 24:30h. \n",
    "\n",
    "After gathering all the text from the news website I translated the text to english, beacause the models that I used did not provided german sentimant analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium as se\n",
    "from time import sleep\n",
    "from tqdm import tqdm as tq\n",
    "\n",
    "# Driver for Firefox, Chrome, Edge, etc.\n",
    "from selenium import webdriver\n",
    "\n",
    "# Mode of locating html elements: ID, CSS_SELECTOR, XPATH, ...\n",
    "from selenium.webdriver.common.by import By               \n",
    "\n",
    "# Using specific keyboard keys like ENTER, ESCAPE, ...\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Methods for dropdown\n",
    "from selenium.webdriver.support.select import Select\n",
    "\n",
    "import pandas as pd\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/nachricht/aktien/aktien-frankfurt-eroeffnung-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/nachricht/aktien/aktien-frankfurt-ausblick-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/nachricht/aktien/10-vor-9-boersenhandel-am-do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/nachricht/aktien/xetra-handel-dax-praesentier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/nachricht/aktien/aktien-frankfurt-schluss-dax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>/nachricht/aktien/aktien-frankfurt-schluss-wal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>/nachricht/aktien/boerse-frankfurt-news-zertif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17000</th>\n",
       "      <td>/nachricht/aktien/boerse-frankfurt-news-markts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17001</th>\n",
       "      <td>/nachricht/aktien/aktien-frankfurt-dax-und-mda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17002</th>\n",
       "      <td>/nachricht/aktien/deutsche-boerse-will-anfang-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17003 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   links\n",
       "0      /nachricht/aktien/aktien-frankfurt-eroeffnung-...\n",
       "1      /nachricht/aktien/aktien-frankfurt-ausblick-da...\n",
       "2      /nachricht/aktien/10-vor-9-boersenhandel-am-do...\n",
       "3      /nachricht/aktien/xetra-handel-dax-praesentier...\n",
       "4      /nachricht/aktien/aktien-frankfurt-schluss-dax...\n",
       "...                                                  ...\n",
       "16998  /nachricht/aktien/aktien-frankfurt-schluss-wal...\n",
       "16999  /nachricht/aktien/boerse-frankfurt-news-zertif...\n",
       "17000  /nachricht/aktien/boerse-frankfurt-news-markts...\n",
       "17001  /nachricht/aktien/aktien-frankfurt-dax-und-mda...\n",
       "17002  /nachricht/aktien/deutsche-boerse-will-anfang-...\n",
       "\n",
       "[17003 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df = pd.read_csv('..\\\\data\\\\links\\\\article_list.tsv', sep='\\t', header=0)\n",
    "article_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Firefox browser to open the URL\n",
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_from_article(driver, article_list):\n",
    "    i = 0\n",
    "    df = pd.DataFrame(columns=['date', 'headline', 'news_text', 'article_url'])\n",
    "    base_url = r'https://www.finanzen.net'\n",
    "\n",
    "    for article in tq(article_list.loc[:, 'links'], desc='Articles'):\n",
    "        article_url = base_url + article\n",
    "        driver.get(article_url)\n",
    "        source = driver.page_source\n",
    "        soup = BeautifulSoup(source, 'html.parser')\n",
    "\n",
    "        # Find date\n",
    "        date = 'None'\n",
    "        dates = soup.find_all('div', class_='grid__item-12')\n",
    "        for date_tag in dates:\n",
    "            if 'Uhr' in date_tag.text:\n",
    "                date = date_tag.text\n",
    "                break\n",
    "\n",
    "        # Find news text\n",
    "        news_text = 'None'\n",
    "        news_container = soup.find_all('div', class_='news-container__text')\n",
    "        if news_container:\n",
    "            news_list = [news.get_text(strip=True) for news in news_container]\n",
    "            news_text = ' '.join(news_list)  # Combine all paragraphs into one string\n",
    "        \n",
    "        # Find headline\n",
    "        headline = 'None'\n",
    "        headlines = soup.find_all('h1')\n",
    "        if headlines:\n",
    "            headline = headlines[0].get_text(strip=True)\n",
    "        \n",
    "        try:\n",
    "            # Add to DataFrame (wrap scalar values in lists)\n",
    "            df = pd.concat([df, pd.DataFrame({'date': [date], \n",
    "                                              'headline': [headline], \n",
    "                                              'news_text': [news_text],\n",
    "                                              'article_url': [article_url]})], ignore_index=True)\n",
    "        except ValueError as e:\n",
    "            print(f'Error: {str(e)}')\n",
    "            print(f'news_text: {news_text}')\n",
    "            print(f'Script stops at article {article}')\n",
    "            print(f'URL: {article_url}')\n",
    "            print(f'headline: {headline}')\n",
    "            print(f'date: {date}')\n",
    "            break\n",
    "        \n",
    "        # Drop duplicates\n",
    "        df.drop_duplicates(subset='news_text', inplace=True)\n",
    "        sleep(1)  # Throttle scraping to avoid bans\n",
    "\n",
    "        i += 1\n",
    "        if i == 500:\n",
    "            break\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Articles:   3%|▎         | 499/17003 [24:37<13:34:29,  2.96s/it]\n"
     ]
    }
   ],
   "source": [
    "df = get_news_from_article(driver=driver, article_list=article_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = len(df)\n",
    "\n",
    "# save the data\n",
    "df.to_csv(f'..\\\\data\\\\DAX-News_n={n}.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue reading please look at the notebook: `translate_news.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".SMA",
   "language": "python",
   "name": ".sma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
